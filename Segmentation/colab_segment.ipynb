{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr-K0n1voOX_",
        "outputId": "6ecb6076-133d-4c90-8e86-2ca6a036032b"
      },
      "outputs": [],
      "source": [
        "# COLAB\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Move segmentation files to dir\n",
        "\n",
        "# from VesselLabPics_PreTrained import FCN_NetModel as FCN\n",
        "# from VesselLabPics_PreTrained import CategoryDictionary as CatDic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp6OJJiLnKJ4"
      },
      "source": [
        "#### Convert a raw video to segmented video + mask frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-pKY173RnKJ7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import FCN_NetModel as FCN # The net Class\n",
        "import CategoryDictionary as CatDic\n",
        "\n",
        "# In function\n",
        "def fluid_segmentation (InputVideo,\n",
        "                        UseGPU=True,\n",
        "                        FreezeBatchNormStatistics=False,\n",
        "                        Trained_model_path=r\"logs//TrainedModelWeiht1m_steps_Semantic_TrainedWithLabPicsAndCOCO_AllSets.torch\"):\n",
        "\n",
        "    OutVideoMain=InputVideo[:-4]+\"_Filled.avi\"\n",
        "    MaskVideoMain=InputVideo[:-4]+\"_Masks.avi\"\n",
        "\n",
        "    Net=FCN.Net(CatDic.CatNum)\n",
        "    if UseGPU==True:\n",
        "        print(\"USING GPU\")\n",
        "        Net.load_state_dict(torch.load(Trained_model_path))\n",
        "    else:\n",
        "        print(\"USING CPU\")\n",
        "        Net.load_state_dict(torch.load(Trained_model_path, map_location=torch.device('cpu')))\n",
        "    \n",
        "    cap = cv2.VideoCapture(InputVideo)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "    MainVideoWriter=None\n",
        "    MaskVideoWriter=None\n",
        "    MaskMain = []\n",
        "\n",
        "    while (cap.isOpened()):\n",
        "        ret, Im = cap.read()\n",
        "        if ret == False:\n",
        "            break\n",
        "        \n",
        "        h,w,d = Im.shape\n",
        "        r = np.max([h,w])\n",
        "\n",
        "        if r > 840:\n",
        "            fr = 840/r\n",
        "            Im = cv2.resize(Im,(int(w*fr),int(h*fr)))\n",
        "        h, w, d = Im.shape\n",
        "        Imgs = np.expand_dims(Im,axis=0)\n",
        "        \n",
        "        if not (type(Im) is np.ndarray):\n",
        "            continue\n",
        "\n",
        "        #................................Make Prediction.............................................................................................................\n",
        "        with torch.autograd.no_grad():\n",
        "            OutProbDict,OutLbDict=Net.forward(Images=Imgs,TrainMode=False,UseGPU=UseGPU, FreezeBatchNormStatistics=FreezeBatchNormStatistics)\n",
        "        #................................Make Prediction.............................................................................................................\n",
        "\n",
        "        my=2\n",
        "        mx=2\n",
        "        OutMain = np.zeros(Im.shape, np.uint8) # 475 840 3\n",
        "        nm = \"Filled\"\n",
        "\n",
        "        y = 0\n",
        "        x = 0\n",
        "        OutMain[:h,:w]=Im\n",
        "        \n",
        "        Lb = OutLbDict[nm].data.cpu().numpy()[0].astype(np.uint8) # mask\n",
        "        if Lb.mean()<0.001:\n",
        "            continue\n",
        "\n",
        "        if nm=='Ignore':\n",
        "            continue\n",
        "\n",
        "        # DISPLAYING SEGMENTED VIDEO (\"Filled\")\n",
        "        ImOverlay1 = Im.copy()\n",
        "        ImOverlay1[:, :, 1][Lb==1] = 0\n",
        "        ImOverlay1[:, :, 0][Lb==1] = 255\n",
        "        # font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        # cv2.putText(ImOverlay1, nm, ( int(w/3), int(h/6)), font, 2, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "        OutMain[h*y:h*(y+1), w*x:w*(x+1)] = ImOverlay1\n",
        "        x+=1\n",
        "        if x>=mx:\n",
        "            x=0\n",
        "            y+=1\n",
        "\n",
        "        # cv2.imshow('Main Classes', OutMain)\n",
        "        # cv2.waitKey(5)\n",
        "\n",
        "        # SAVE \"Filled\"\n",
        "        if MainVideoWriter is None:\n",
        "            h, w, d = OutMain.shape\n",
        "            MainVideoWriter = cv2.VideoWriter(OutVideoMain, fourcc, 30.0, (w, h))\n",
        "        MainVideoWriter.write(OutMain)\n",
        "\n",
        "        #-------------------------------------------------------------------------------------------------------------------------\n",
        "        # FOR MASK VIDEO\n",
        "        MaskMain.append (Lb)\n",
        "\n",
        "    # SAVE Mask video\n",
        "    MaskStack = np.stack(MaskMain)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\") # grayscale\n",
        "    # h,w,d = OutMain.shape\n",
        "    if MaskVideoWriter is None:\n",
        "        MaskVideoWriter = cv2.VideoWriter (MaskVideoMain, fourcc, 30.0, (w,h), isColor=False)\n",
        "\n",
        "    for i, mask in enumerate (MaskStack):\n",
        "        mask = (mask * 255).astype(np.uint8)\n",
        "        MaskVideoWriter.write (mask)\n",
        "\n",
        "    #-----------------------------------------------------------------------------------------------------------------------------\n",
        "    print(\"Finished\")\n",
        "    MainVideoWriter.release()\n",
        "    MaskVideoWriter.release()\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jhp98\\anaconda3\\envs\\DL\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\jhp98\\anaconda3\\envs\\DL\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USING GPU\n",
            "Finished\n"
          ]
        }
      ],
      "source": [
        "InputVideo=r\"C:/Users/jhp98/OneDrive/Desktop/Viscosity Autoencoder/fortest.mp4\"\n",
        "Trained_model_path =r\"logs/trained_2023.torch\"\n",
        "\n",
        "fluid_segmentation (InputVideo, Trained_model_path=Trained_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3exPVcVDqOTW",
        "outputId": "6b7bb3c4-914e-4dbc-82df-b8666f68c895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USING GPU\n",
            "Finished\n",
            "w9.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "m4.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "w8.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "m3.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "m10.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "m8.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "w2.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "w4.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "m9.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "w1.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "w7.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "w3.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "m5.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "m2.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "m7.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "m1.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "w5.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "w10.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "w6.mp4 segmented and saved\n",
            "USING GPU\n",
            "Finished\n",
            "m6.mp4 segmented and saved\n"
          ]
        }
      ],
      "source": [
        "from os.path import join\n",
        "\n",
        "cropped_videos_path = \"/content/VesselLabPics_PreTrained/cropped\"\n",
        "cropped_videos_filenames = os.listdir (cropped_videos_path)\n",
        "cropped_videos_dir = [join (cropped_videos_path, cropped_videos_filenames[i]) for i in range(len(cropped_videos_filenames))]\n",
        "\n",
        "for i, video in enumerate(cropped_videos_dir):\n",
        "  fluid_segmentation (video, Trained_model_path=r\"/content/VesselLabPics_PreTrained/logs/TrainedModelWeiht1m_steps_Semantic_TrainedWithLabPicsAndCOCO_AllSets.torch\")\n",
        "  print (f\"{cropped_videos_filenames[i]} segmented and saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sLwTx2jtrH8"
      },
      "outputs": [],
      "source": [
        "# moving results\n",
        "all_filenames = os.listdir (cropped_videos_path)\n",
        "all_dir = [join (cropped_videos_path, all_filenames[i]) for i,vid in enumerate(all_filenames) if vid.endswith(\".avi\")]\n",
        "move_dir = join(\"/content/VesselLabPics_PreTrained/out_dir\", f.split(\"/\")[-1])\n",
        "\n",
        "for f in all_dir:\n",
        "  move_dir = join(\"/content/VesselLabPics_PreTrained/out_dir\", f.split(\"/\")[-1])\n",
        "  os.rename(f, move_dir)\n",
        "\n",
        "\n",
        "# saving results\n",
        "saved_dir = \"/content/VesselLabPics_PreTrained/out_dir\"\n",
        "to_download = os.listdir(saved_dir)\n",
        "print (f\"file to be moved to Drive: \\n{to_download}\")\n",
        "\n",
        "for i, vid in enumerate (to_download):\n",
        "  !cp /content/VesselLabPics_PreTrained/out_dir/{vid} \"/content/drive/MyDrive/oscil_segnpz\"\n",
        "  print (f\"{vid} saved to Drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIe8FjconKJ8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "DL",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
